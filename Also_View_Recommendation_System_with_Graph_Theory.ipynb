{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Also-View Recommendation System with Graph Theory.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPbts+U5AwmhC69SZNCQVKH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/analytics-vidhya/also-view-recommendation-system-with-graph-theory-e2f098455519)"
      ],
      "metadata": {
        "id": "23Q4QMthzWtW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u8GtxGyGys9L"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools \n",
        "import math\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import community.community_louvain as community_louvain\n",
        "\n",
        "data_path = '../data/ml-100k/u.data'\n",
        "\n",
        "# load train and test data\n",
        "df = pd.read_csv(data_path, delimiter = '\\t', names = ['userid', 'itemid', 'rating', 'timestamp'])\n",
        "df = df[['userid', 'itemid', 'rating']]\n",
        "\n",
        "# To build the graph with high correlation and reduce the complexity of the network, \n",
        "# we set the minimum rating to be 5.\n",
        "min_rating= 5\n",
        "rated_movie = df.drop(df[df['rating']<min_rating].index)\n",
        "\n",
        "rated_movie.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_itemlist = rated_movie.groupby('userid')['itemid'].apply(list)\n",
        "\n",
        "edge_dict = defaultdict(lambda: 0)\n",
        "for item_list in user_itemlist:\n",
        "    item_list = sorted(item_list)\n",
        "    pairs = itertools.combinations(item_list, 2)\n",
        "    for pair in list(pairs):\n",
        "        edge_dict[pair] += 1\n",
        "        \n",
        "edges = [tuple([e[0], e[1], edge_dict[e]]) for e in edge_dict]\n",
        "\n",
        "print(len(edge_dict.keys()))\n",
        "print(edges[:5])"
      ],
      "metadata": {
        "id": "I9Eo30snzNCL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g= nx.Graph()\n",
        "g.add_weighted_edges_from(edges)\n",
        "print(\"Total number of graph nodes:\", g.number_of_nodes())\n",
        "print(\"Total number of graph edges:\", g.number_of_edges())\n",
        "\n",
        "degrees = []\n",
        "for node in g.nodes:\n",
        "    degrees.append(g.degree[node])\n",
        "\n",
        "print(\"Average node degree:\", round(sum(degrees) / len(degrees), 2))\n",
        "\n",
        "partitions = community_louvain.best_partition(g)\n",
        "values = list(partitions.values())\n",
        "print('Number of communities:', len(np.unique(values)))"
      ],
      "metadata": {
        "id": "MUF3BfuizOO2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_col = [\"unknown\",\"Action\",\"Adventure\",\"Animation\",\"Children's\",\"Comedy\",\"Crime\",\"Documentary\",\"Drama\",\"Fantasy\",\"Film-Noir\",\"Horror\",\"Musical\",\"Mystery\",\"Romance\",\"Sci-Fi\",\"Thriller\",\"War\",\"Western\"]\n",
        "\n",
        "column_arr = [\"movie id\",\"movie title\",\"release date\",\"video release date\",\"IMDb URL\"] + category_col\n",
        "item_data = pd.read_csv('../data/ml-100k/u.item', delimiter = '|', names =column_arr, encoding='latin1')\n",
        "\n",
        "item_dict = defaultdict(lambda:[])\n",
        "item_data = item_data.to_numpy()\n",
        "\n",
        "for d in item_data:\n",
        "    res = []\n",
        "    for indx in range(2,len(d)):\n",
        "        if d[indx] == 1:\n",
        "            res.append(column_arr[indx])\n",
        "    \n",
        "    item_dict[d[0]] = res\n",
        "\n",
        "res_dict = defaultdict(lambda: [])\n",
        "for k in partitions:\n",
        "    res_dict[partitions[k]].append(item_dict[k])\n",
        "\n",
        "# print the first cluster\n",
        "res_dict[0]"
      ],
      "metadata": {
        "id": "bumLcBlezPjU"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}